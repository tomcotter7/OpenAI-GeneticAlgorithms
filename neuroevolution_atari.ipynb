{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomcotter7/OpenAI-GeneticAlgorithms/blob/main/neuroevolution_atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpNP8jpKjsJ"
      },
      "source": [
        "# Required Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bwk-P1XdImw9"
      },
      "outputs": [],
      "source": [
        "#Include this at the top of your colab code\n",
        "import os\n",
        "if not os.path.exists('.mujoco_setup_complete'):\n",
        "  # Get the prereqs\n",
        "  !apt-get -qq update\n",
        "  !apt-get -qq install -y libosmesa6-dev libgl1-mesa-glx libglfw3 libgl1-mesa-dev libglew-dev patchelf\n",
        "  # Get Mujoco\n",
        "  !mkdir ~/.mujoco\n",
        "  !wget -q https://mujoco.org/download/mujoco210-linux-x86_64.tar.gz -O mujoco.tar.gz\n",
        "  !tar -zxf mujoco.tar.gz -C \"$HOME/.mujoco\"\n",
        "  !rm mujoco.tar.gz\n",
        "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
        "  !echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.mujoco/mujoco210/bin' >> ~/.bashrc \n",
        "  !echo 'export LD_PRELOAD=$LD_PRELOAD:/usr/lib/x86_64-linux-gnu/libGLEW.so' >> ~/.bashrc\n",
        "  # THE ANNOYING ONE, FORCE IT INTO LDCONFIG SO WE ACTUALLY GET ACCESS TO IT THIS SESSION\n",
        "  !echo \"/root/.mujoco/mujoco210/bin\" > /etc/ld.so.conf.d/mujoco_ld_lib_path.conf\n",
        "  !ldconfig\n",
        "  # Install Mujoco-py\n",
        "  !pip3 install -U 'mujoco-py<2.2,>=2.1'\n",
        "  # run once\n",
        "  !touch .mujoco_setup_complete\n",
        "\n",
        "try:\n",
        "  if _mujoco_run_once:\n",
        "    pass\n",
        "except NameError:\n",
        "  _mujoco_run_once = False\n",
        "if not _mujoco_run_once:\n",
        "  # Add it to the actively loaded path and the bashrc path (these only do so much)\n",
        "  try:\n",
        "    os.environ['LD_LIBRARY_PATH']=os.environ['LD_LIBRARY_PATH'] + ':/root/.mujoco/mujoco210/bin:/usr/lib/nvidia'\n",
        "  except KeyError:\n",
        "    os.environ['LD_LIBRARY_PATH']='/root/.mujoco/mujoco210/bin:/usr/lib/nvidia'\n",
        "  try:\n",
        "    os.environ['LD_PRELOAD']=os.environ['LD_PRELOAD'] + ':/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
        "  except KeyError:\n",
        "    os.environ['LD_PRELOAD']='/usr/lib/x86_64-linux-gnu/libGLEW.so'\n",
        "  # presetup so we don't see output on first env initialization\n",
        "  import mujoco_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVZ-MnjH10az"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ie_foh88aY3K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout\n",
        "import random\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.atari_wrappers import *\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPkh61RhKXQZ"
      },
      "source": [
        "# Agent Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XLyAMYoDKct4"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, name):\n",
        "\n",
        "        self.nn = self.build_model()\n",
        "        self.name = name\n",
        "\n",
        "    def update_name(self, new_name):\n",
        "      self.name = new_name\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(Conv2D(32, [8,8], strides=(4,4), activation=\"relu\", input_shape=(84,84,1)))\n",
        "        model.add(Conv2D(64, [4,4], strides=(4,4), activation=\"relu\"))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(256,activation=\"relu\"))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(6))\n",
        "        return model\n",
        "\n",
        "    def update_weights(self, new_weights):\n",
        "        for index, layer in enumerate(self.nn.layers):\n",
        "            layer.set_weights(new_weights[index])\n",
        "\n",
        "    def get_weights(self):\n",
        "        return [layer.get_weights() for layer in self.nn.layers]\n",
        "    \n",
        "    \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDNBVNAOImjU"
      },
      "source": [
        "# Runner Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KwSg4sXSIpm9"
      },
      "outputs": [],
      "source": [
        "class Runner:\n",
        "\n",
        "  def __init__(self, env, generations, experiences_per_gen=8, pop_size=10, initial_gen=None, no_limit=False):\n",
        "    self.env = WarpFrame(env, 84)\n",
        "    if initial_gen == None:\n",
        "      self.gen = self.create_initial_gen(pop_size)\n",
        "    else:\n",
        "      self.gen = initial_gen\n",
        "    self.generations = generations\n",
        "    self.experience = experiences_per_gen\n",
        "    self.nolimit = no_limit\n",
        "\n",
        "  # function to create an initial generation\n",
        "  def create_initial_gen(self, n):\n",
        "    return [Agent(\"agent\"+str(i)) for i in range(n)]\n",
        "  \n",
        "\n",
        "  # function to run a generation across an environment\n",
        "  def run_gen_env(self, gen):\n",
        "    results = []\n",
        "    for agent in gen:\n",
        "        nn_specific_results = [self.run_env(self.env, agent.nn) for i in range(self.experience)]\n",
        "        print(\"Agent {} with scores {}\".format(agent.name, nn_specific_results))\n",
        "        results.append((agent.name, 0.3 * np.median(nn_specific_results, axis=0) + 0.7 * np.mean(nn_specific_results, axis=0)))\n",
        "    print(\"Results {}\".format(results))\n",
        "    return gen, results\n",
        "   \n",
        "\n",
        "  # function to run an agent in an environment\n",
        "  def run_env(self, env, nn):\n",
        "    obs = env.reset()\n",
        "    reward = -1\n",
        "    award = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = nn.predict(np.array([obs]))\n",
        "        action = np.argmax(action, axis=1)\n",
        "        obs, reward, done, info = env.step(action[0])\n",
        "        if info['episode_frame_number'] >= 15000:\n",
        "          break\n",
        "        if not self.nolimit and info['lives'] < 3:\n",
        "          break\n",
        "        award += reward\n",
        "\n",
        "    return award\n",
        "  \n",
        "  # crossover functions\n",
        "  def crossover_lwb(self, wbs1, wbs2, cr):\n",
        "    for j in range(len(wbs1)):\n",
        "      chance = random.uniform(0,1)\n",
        "      if chance < cr:\n",
        "        temp = wbs1[j].copy()\n",
        "        wbs1[j] = wbs2[j]\n",
        "        wbs2[j] = temp\n",
        "\n",
        "    return wbs1, wbs2    \n",
        "\n",
        "  def crossover(self, weights1, weights2, cr):\n",
        "    new_weights1 = []\n",
        "    new_weights2 = []\n",
        "    for i in range(len(weights1)):\n",
        "      if weights1[i] != []:\n",
        "        lw1, lw2 = self.crossover_lwb(weights1[i][0], weights2[i][0], cr)\n",
        "        lb1, lb2 = self.crossover_lwb(weights1[i][1], weights2[i][1], cr)\n",
        "        new_weights1.append([lw1, lb1])\n",
        "        new_weights2.append([lw2, lb2])\n",
        "      else:\n",
        "        new_weights1.append([])\n",
        "        new_weights2.append([])\n",
        "    return new_weights1, new_weights2\n",
        "\n",
        "  \n",
        "\n",
        "  def mutate_wb(self, lw, mr):\n",
        "    chance = random.uniform(0, 1)\n",
        "    if chance < mr:\n",
        "      # change by a percentage\n",
        "      lw = np.vectorize(lambda x: np.multiply(x, random.uniform(0.5, 1.5)))(lw)\n",
        "\n",
        "      # change the sign of the weights\n",
        "      # lw = np.vectorize(lambda x: np.multiply(x, -1))(lw)\n",
        "\n",
        "      # replace with a random value ?\n",
        "      # lw = np.random.random(lw.shape)\n",
        "\n",
        "    return lw\n",
        "\n",
        "  def mutate_lw(self, lw, mr):\n",
        "    return [self.mutate_wb(wb, mr) for wb in lw]\n",
        "\n",
        "  def mutate(self, weights, mr):\n",
        "    return [self.mutate_lw(lw, mr) for lw in weights]\n",
        "  \n",
        "  def just_mutation(self, agent, mr):\n",
        "    new_weights = self.mutate(agent.get_weights(), mr)\n",
        "    child = Agent(\"child\")\n",
        "    child.update_weights(new_weights)\n",
        "    return child\n",
        "\n",
        "\n",
        "  def run_evolution(self, agent1, agent2, cr, mr):\n",
        "    cweights1, cweights2 = self.crossover(agent1.get_weights(), agent2.get_weights(), cr)\n",
        "\n",
        "    mweights1 = self.mutate(cweights1, mr)\n",
        "    mweights2 = self.mutate(cweights2, mr)\n",
        "\n",
        "    c1 = Agent(\"child\")\n",
        "    c2 = Agent(\"child\")\n",
        "\n",
        "    c1.update_weights(mweights1)\n",
        "    c2.update_weights(mweights2)\n",
        "\n",
        "    return c1, c2\n",
        "\n",
        "  def get_best_n_names(self, lst, n=2):\n",
        "    best_n_names = [name for name, _, in sorted(lst, key=lambda x: x[1])[-n:]]\n",
        "    return best_n_names\n",
        "\n",
        "\n",
        "  def get_new_gen(self, gen_reward, g):\n",
        "\n",
        "    new_gen = []\n",
        "\n",
        "    mr = 0.3 / math.sqrt(g + 1)\n",
        "    cr = 0.35\n",
        "\n",
        "    print(\"Current MR: {} and Current CR: {}\".format(mr, cr))\n",
        "\n",
        "    # initially let's perform elitism and select the best 2 individuals.\n",
        "    best_2_names = self.get_best_n_names(gen_reward)\n",
        "    print(\"2 best agents from generation:\", best_2_names)\n",
        "    best_agents = [self.just_mutation(indiv, mr=0.001) for indiv in self.gen if indiv.name in best_2_names]\n",
        "    new_gen.append(best_agents[0])\n",
        "    new_gen.append(best_agents[1])\n",
        "\n",
        "    # now let's perform tournament selection n times\n",
        "\n",
        "    for i in range(int(len(self.gen) / 2) - 1):\n",
        "        tournament_1 = random.sample(gen_reward, int(len(gen_reward) / 2))\n",
        "        # take the two best parents from this tournament.\n",
        "        best_2 = self.get_best_n_names(tournament_1)\n",
        "        agents = [indiv for indiv in self.gen if indiv.name in best_2]\n",
        "        # perform crossover\n",
        "        c1, c2 = self.run_evolution(agents[0], agents[1], cr, mr)\n",
        "        new_gen.append(c1)\n",
        "        new_gen.append(c2)\n",
        "    \n",
        "    \n",
        "    for index, agent in enumerate(new_gen):\n",
        "      new_name = \"agent{}\".format(str(index))\n",
        "      agent.update_name(new_name)\n",
        "  \n",
        "\n",
        "    self.gen = new_gen\n",
        "\n",
        "  def best_score(self, gen_reward):\n",
        "    best_score = [score for _, score in sorted(gen_reward, key=lambda x: x[1])][-1]\n",
        "    return best_score\n",
        "  \n",
        "\n",
        "  def run_genetic_algorithm(self):\n",
        "    best_scores = []\n",
        "    mean_scores = []\n",
        "    median_scores = []\n",
        "    self.gen, gen_reward = self.run_gen_env(self.gen)\n",
        "    for g in range(self.generations):\n",
        "      print(\"Generation %i\" % (g))\n",
        "      best_scores.append(self.best_score(gen_reward))\n",
        "      mean_scores.append(np.mean([score for _, score in gen_reward]))\n",
        "      median_scores.append(np.median([score for _, score in gen_reward]))\n",
        "      print(\"Scores:\", gen_reward)\n",
        "      gen = self.get_new_gen(gen_reward, g)\n",
        "      self.gen, gen_reward = self.run_gen_env(self.gen)\n",
        "    \n",
        "    return self.gen, gen_reward, best_scores, mean_scores, median_scores\n",
        "  \n",
        "\n",
        "  def run_multiple_times(self, model):\n",
        "    return [self.run_env(self.env, model) for i in range(self.experience)]\n",
        "      \n",
        "\n",
        "  def run_random_algorithm(self, env):\n",
        "    obs = env.reset()\n",
        "    award = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "      action = env.action_space.sample()\n",
        "      obs, reward, done, info = env.step(action)\n",
        "      if info['episode_frame_number'] >= 15000:\n",
        "          break\n",
        "      award += reward\n",
        "\n",
        "    return award\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsAbwZ6GcM66"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqbPihXlWtCY"
      },
      "outputs": [],
      "source": [
        "ENV = gym.make(\"SpaceInvaders-v4\")\n",
        "\n",
        "sp_runner = Runner(ENV, generations=25, experiences_per_gen=10, pop_size=12)\n",
        "gen, gen_reward, best_scores, mean_scores, median_scores = sp_runner.run_genetic_algorithm()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(best_scores, label=\"Best Score\")\n",
        "plt.plot(mean_scores, label=\"Mean Score\")\n",
        "plt.plot(median_scores, label=\"Median Score\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "final_best_agent_name = max(gen_reward, key=lambda x: x[1])[0]\n",
        "best_agent = [agent for agent in gen if agent.name == final_best_agent_name][0]\n",
        "\n",
        "best_agent.nn.save(\"/content/drive/MyDrive/year3/dia/best_agent\")\n",
        "best_agent.nn.save_weights(\"/content/drive/MyDrive/year3/dia/best_agent_ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_nn = tf.keras.models.load_model(\"/content/drive/MyDrive/year3/dia/best_agent\")\n",
        "# best_nn = best_agent.nn\n",
        "\n",
        "C_ENV = gym.make(\"Carnival-v4\")\n",
        "SP_ENV = gym.make(\"SpaceInvaders-v4\")\n",
        "DA_ENV = gym.make(\"DemonAttack-v4\")\n",
        "\n",
        "sp_runner = Runner(SP_ENV, generations=1, experiences_per_gen=10, pop_size=1, no_limit=True)\n",
        "da_runner = Runner(DA_ENV, generations=1, experiences_per_gen=10, pop_size=1, no_limit=True)\n",
        "c_runner = Runner(C_ENV, generations=1, experiences_per_gen=10, pop_size=1, no_limit=True)\n",
        "\n",
        "random_agent = Agent(\"random\")\n",
        "random_nn = random_agent.nn\n",
        "\n",
        "random_results = sp_runner.run_multiple_times(model=random_nn)\n",
        "model_results = sp_runner.run_multiple_times(model=best_nn)\n",
        "\n",
        "print(\"Space Invaders:\")\n",
        "\n",
        "print(\"Random Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(random_results), np.median(random_results), max(random_results)))\n",
        "print(\"Model Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(model_results), np.median(model_results), max(model_results)))\n",
        "\n",
        "print(\"-----------------\")\n",
        "\n",
        "print(\"Demon Attack\")\n",
        "\n",
        "random_results = da_runner.run_multiple_times(model=random_nn)\n",
        "model_results = da_runner.run_multiple_times(model=best_nn)\n",
        "\n",
        "print(\"Random Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(random_results), np.median(random_results), max(random_results)))\n",
        "print(\"Model Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(model_results), np.median(model_results), max(model_results)))\n",
        "\n",
        "print(\"--------------\")\n",
        "\n",
        "print(\"Carnival\")\n",
        "\n",
        "random_results = c_runner.run_multiple_times(model=random_nn)\n",
        "model_results = c_runner.run_multiple_times(model=best_nn)\n",
        "\n",
        "print(\"Random Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(random_results), np.median(random_results), max(random_results)))\n",
        "print(\"Model Results: Mean: {}, Median: {}, Best: {}\".format(np.mean(model_results), np.median(model_results), max(model_results)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yqQNNQkeybpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kFpNP8jpKjsJ",
        "wPkh61RhKXQZ"
      ],
      "name": "neuroevolution-atari.ipynb",
      "provenance": [],
      "mount_file_id": "1oPO1v3z9gGQO31guKCHiD3i6LLdMcq90",
      "authorship_tag": "ABX9TyP+R7bcLbatz3kKz9EioDfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}